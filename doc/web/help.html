<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" href="style.css" type="text/css" media="screen" />
    <title>visiongrader help</title>
  </head>
  <body>
  <div id="content">
    <h1>
      visiongrader help
    </h1>
    <h2>
      Intoduction
    </h2>
    <p><i>visiongrader</i> is a scoring tool for detection algorithms.
    It is mainly used with face and pedestrians recognition, but
    nothing prevents you from using it with another type of data,
    provided you write a parser for the data.</p>
    <p>Both the parser and the comparator can easily be changed, so
    it can adapt to quite a large range of situations. You can either
    score a single result or, if you got the confidence of the results,
    plot a ROC or a DET curve.</p>
    <h2>
      Usage
    </h2>
    <p>For the time being, <i>visiongrader</i> is a command-line program.
    You can run it bt typing either <code>python main.py</code> or
    simply <code>./main.py</code> if it has been correctly chmoded.
    The options depend on the kind of data you are scoring.</p>
    <h3>
      Common options
    </h3>
    <p>If you do not specify <opt>--roc</opt> or <opt>--det</opt>, it will just score
    a single file. See the next section to plot curves from confidences.</p>
    <p><ul>
      <li><opt>--help</opt> : displays the help.</li>
      <li><opt>--input</opt> : the path to the input file. It is the file to score.</li>
      <li><opt>--input_parser</opt> : the parser to use to read the input file.</li>
      <li><opt>--groundtruth</opt> : the path to the groundtruth file.</li>
      <li><opt>--groundtruth_parser</opt> : the parser to use to read the
      groundtruth file</li>
      <li><opt>--parser_dir</opt> : the path to the directory where the parsers are
      located. If not specified, it is set to <i>./parsers</i> .</li>
      <li><opt>--comparator</opt> : the comparator to use. The comparator role is
      to tell if two boxes (or whatever object is used to describe the
      detections) match.</li>
      <li><opt>--comparator_dir</opt> : the path to the directory there the parsers
      are located. If not specified, it is set to <i>./comparators</i> .</li>
      <li><opt>--crawl</opt> : instead of an input file, use an input directory.
      It will only have an effect if the input parser has a crawl
      support. The comportement can differ from a parser to another,
      but the idea is to crawl into the directory and concatenate all
      the result files.</li>
    </ul></p>
    <h3>
      ROC/DET options
    </h3>
    <p>If you specify <opt>--roc</opt> or <opt>--det</opt>, then more options become
    available, in addition to the previous ones. If one of these options are
    set without any of <opt>--roc</opt> or <opt>--det</opt> set, it will either be
    ignored or raise an error.
    <p><ul>
      <li><opt>--roc</opt> : make a ROC curve.</li>
      <li><opt>--det</opt> : make a DET curve.</li>
      <li><opt>--confidence_min</opt> : the mininal confidence to consider when
      making the curve.</li>
      <li><opt>--confidence_max</opt> : the maxinal confidence to consider when
      making the curve.</li>
      <li><opt>--sampling</opt> : the number of points used to make the curve.</li>
      <li><opt>--show-no-curve</opt> : does not display the curve when computed.</li>
      <li><opt>--saving-file</opt> : by default, the curve is not saved. If you specify
      file with this options, the curve is saved in that file.</li>
      <li><opt>--xmin</opt> : the minimal x on the displayed curve.</li>
      <li><opt>--xmax</opt> : the maximal x on the displayed curve.</li>
      <li><opt>--ymin</opt> : the minimal y on the displayed curve.</li>
      <li><opt>--ymax</opt> : the maximal y on the displayed curve.</li>
    </ul></p>
    <h3>
      Print saved/multiple curves
    </h3>
    <p>Saved curves are stored in a python pickle format, so you cannot read
    them easily. That's why there is the <i>plotpickle.py</i> module. It
    allows you to plot one or several saved curves on the same graph.
    Basically, you use it typing</p>
    <p><code>python plotpickle.py [options] file1 [file2 [file3...]]</code></p>
    <p>There are several options you can use :
    <ul>
      <li><opt>--help</opt> : displays the help.</li>
      <li><opt>--main_curve</opt> : if there is a curve you want to highlight,
      specify the name of its file with this option. Don't forget you still have
      to put the name just like any curve, so the file name will appear twice.</li>
      <li><opt>--xlegend</opt> : the legend on the x axis.</li>
      <li><opt>--ylegend</opt> : the legend on the y axis.</li>
      <li><opt>--xmin</opt> : the minimal x on the graph.</li>
      <li><opt>--xmax</opt> : the maximal x on the graph.</li>
      <li><opt>--ymin</opt> : the minimal y on the graph.</li>
      <li><opt>--ymax</opt> : the maximal y on the graph.</li>
    </ul></p>
    <h2>
      Examples
    </h2>
    <p>Suppose you want to plot a DET curve from data generated by
    <a href = "http://eblearn.sourceforge.net/">eblearn</a>, on the
    <a href = "http://pascal.inrialpes.fr/data/human/">INRIA pedestrian dataset</a>.
    We assume that the eblearn data are named <i>bbox.txt</i>, and that
    the INRIA dataset is located at <i>data/INIRA</i>. We want to use the
    <i>overlap50percent</i> comparator. Then the command line would be :</p>
    <p><code>python main.py --input eblearn --input_parser eblearn --groundtruth
    data/INRIA --groundtruth_parser INRIA --comparator overlap50percent --det</code></p>
    <p>Suppose now you want to save the curve in the file <i>eblearn-inria.curve</i>,
    and you now want a ROC curve. You also want only 100 points on the curve :</p>
    <p><code>python main.py --input eblearn --input_parser eblearn --groundtruth
    data/INRIA --groundtruth_parser INRIA --comparator overlap50percent --roc
    --saving-file eblearn-inria.curve --sampling 100</code></p>
    <p>If you want to plot the curves <i>eblearn-inria.curve</i>, <i>foo.curve</i>
    and <i>bar.curve</i> on the same graph, with <i>x</i> between 0 and 100,
    and <i>eblearn-inria.curve</i> being highlighted, you type :</p>
    <p><code>python plotpickle.py --main_curve eblearn-inria.curve --xmin 0 --xmax 100
    eblearn-inria.curve foo.curve bar.curve</code></p>
    <h2>
      Standard comparators
    </h2>
    The standard comparators mainly use boxes. If the object has no box (like the
    groundtruth for the CMU face dataset), it generates a box from the data, which
    could lack precision.
    <p><ul>
      <li><opt>overlap</opt> : it compares two boxes and returns true iff the boxes
      overlap, even if it is only one pixel.</li>
      <li><opt>overlap50percent</opt> : it compares two boxes A and B, and returns true
      iff the boxes overlap, and <br/>
      area(inter(A, B))/area(union(A, B)) > 0.5 . Actually,
      you can change 0.5 to any value simply by editing the source file.</li>
      <li><opt>garcia-delakis</opt> : this is a face comparator found in the article 
      <i>Convolutional Face Finder : A Neural Architecture for Fast and Robust
      Face Detection</i> by C. Garcia and M. Delakis. It compares a box with a face,
      and returns true iff the eyes and the mouth are in the box, and if the box area
      does not exceed <i>a</i> times the size of a groundtruth box. <i>a</i> can be adjusted
      in the file.</li>
    </ul></p>
    <h2>
      Writing modules
    </h2>
    <h3>
      Parsers
    </h3>
    <p>By default, parsers are stored in the <i>parsers</i> directory. A parser
    <i>foo.py</i> will be named <i>foo</i> when used. Every <i>.py</i> file
    in the parser directory will be considerated as a parser, and an error
    will occur if it does not have the right sturcture.</p>
    <p>A parser sould at least have one of the following functions, and can have
    several of them, according to its usage.
    <ul>
      <li><code>parse(filename, crawl = False)</code> : if <code>crawl</code> is set to False,
      it should parse a single file, if it is set to True, it can either look for
      several files in the <code>filename</code> directory, or raise an error if the
      crawl mode is not supported. It should return a <code>dataset.DataSet</code> object.</li>
      <li><code>parse_multi(filename, crawl = False)</code> : it has the same comportement than
      <code>parse</code>, except than it takes confidences into account, and returns a
      <code>dataset.DataSetMulti</code> object.</li>
    </ul></p>
    <h3>
      Comparators
    </h3>
    <p>Comparators are similar to parsers in the way they are handled. They are
    in the <i>comparators</i> folder, and they are named by their file name without
    the <i>.py</i> .</p>
    <p>The only recognized function in a comparator is
    <code>compare_datasets(toscore, groundtruth)</code>, which takes two
    <code>dataset.DataSet</code> and returns a <code>result.DataSetResult</code> .</p>
    <p>There are several common and useful functions for comparators that can be
    found in <code>comparator_helpers</code> .</p>
  </div>
  </body>
</html>